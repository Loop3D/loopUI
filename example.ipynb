{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty indicators for property fields\n",
    "\n",
    "In the geosciences, uncertainty quantification relies on ensemble of models / realizations. \n",
    "\n",
    "The type of variables analysed can be viewed as:\n",
    " - Inputs for forward models (such as geomodelling, geophysical, hyrogeological, ... engines )\n",
    " - Model outputs\n",
    ", which can be either of them e.g. density can be the output of a geo-modelling engine and an input for a geo-physical simulation.\n",
    "\n",
    "Or they can also be depicted as:\n",
    " - Categorical: \n",
    "     - lithocode\n",
    "     - any classification code  \n",
    " - Continuous: \n",
    "     - potential fields (from implicit modeling)\n",
    "     - hydro-, geo-, petro-, physical- properties (e.g. porosity, hydraulic conductivity, density, mag, velocity, ...)\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning:</b> Indicators based on discrete or categorical variable require a standard classification for the realizations of the considered ensemble. Note that it is not the case for the 1 million noddyverse models, but we will ignore this fact, just to illustrate the computation of the indicators. \n",
    "</div>\n",
    "    \n",
    "Here, we focus on uncertainty quantification of property field and for the purpose of illustration we will use the following: \n",
    " - 3D litho code (categorical)\n",
    " - 3D density (continuous)\n",
    " - 3D magnetic susceptipility (continuous)\n",
    " - 2D gravity residuals (continuous)\n",
    " - 2D magnetic residuals (continuous)\n",
    "\n",
    "Given an ensemble of property fields, there are two main ways to compute uncertainty indicators:\n",
    " - based on local cell comparison throughout the ensemble of realizations (e.g. Cardinality or Entropy) - note that it requires the same meshing for all realizations of the ensemble\n",
    " - using distances (Wasserstein, Jenson-Shannon, Fisher information metric ...) between summary statistics (e.g. semi-variogram, connectivity functions, MPH, topology indicators (matrices+....), persistent homology... that are computed for each realization) - in that case meshing might vary, and it enables the classification of realizations of an ensemble into clusters\n",
    "\n",
    "One can note that cell-based uncertainty indicators will provide information about the local spatial variability of the property fields while distance-based ones will inform more about structural dis-similarity of the property fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "To run these notebooks:\n",
    "% - noddyverse (available at https://github.com/Loop3D/noddyverse) \n",
    " - numpy\n",
    " - pandas\n",
    " - urllib\n",
    " - gzip\n",
    " - matplotlib\n",
    " - datetime\n",
    " - pickle\n",
    " - seaborn\n",
    " - sklearn\n",
    " - scipy\n",
    " - pywt\n",
    " - mpl_toolkits\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download property fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906573                  FOLD FOLD FOLD\n",
       "774062                  TILT PLUG TILT\n",
       "333151                  DYKE FOLD TILT\n",
       "81103     UNCONFORMITY FOLD SHEAR-ZONE\n",
       "407249                 FOLD FAULT FOLD\n",
       "232239                 TILT FAULT TILT\n",
       "132490                FAULT FAULT PLUG\n",
       "53428            FAULT SHEAR-ZONE FOLD\n",
       "725608                 FAULT FOLD TILT\n",
       "11428     UNCONFORMITY DYKE SHEAR-ZONE\n",
       "Name: event_all, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the noddyverse folder locations to the path\n",
    "# import sys\n",
    "# sys.path.append(\"C:\\\\Users\\\\00102908\\\\utilities\\\\noddyverse-main\\\\\")\n",
    "# sys.path.append(\"C:\\\\Users\\\\00102908\\\\utilities\\\\noddyverse-main\\\\model_list\\\\\")\n",
    "\n",
    "# import modules\n",
    "# from noddyverse import rand_cmap,get_gz_array\n",
    "from uncertaintyIndicators import rand_cmap,get_gz_array\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from urllib.request import urlopen\n",
    "import gzip\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "picklefilename = \"./pickledata/testing-model-subset.pickle\" # to save the downloaded data into existing folder\n",
    "import os\n",
    "if not os.path.exists('pickledata'):\n",
    "    os.makedirs('pickledata')\n",
    "if not os.path.exists('models.csv'):\n",
    "    import shutil\n",
    "    with gzip.open('models.csv.gz', 'rb') as f_in:\n",
    "        with open('models.csv', 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "# initialization\n",
    "nbsamples = 10 # fixed for the demonstration of indicator computations\n",
    "myseed=12345 # repeatable demo\n",
    "cldurl = 'https://cloudstor.aarnet.edu.au/plus/s/8ZT6tjOvoLWmLPx/download?path=%2f' # cloudstor url prefix\n",
    "[nz,ny,nx]=[200,200,200]\n",
    "\n",
    "rng = default_rng(myseed)\n",
    "# unzip models.zip if models.csv does not exist\n",
    "\n",
    "\n",
    "models=pd.read_csv('models.csv')\n",
    "nbmodels = len(models)\n",
    "models['cldurl'] = cldurl\n",
    "models['url']= models['cldurl']+ models['event03']+'_'+ models['event04']+'_'+ models['event05']+'&files='+models['root'].str.rpartition('/')[2]\n",
    "\n",
    "cmap = rand_cmap(100, type='bright', first_color_black=False, last_color_black=False, verbose=False)\n",
    "\n",
    "mag_all = np.zeros((ny,nx,nbsamples))*np.nan\n",
    "grv_all = np.zeros((ny,nx,nbsamples))*np.nan\n",
    "mod_all = np.zeros((nz,ny,nx,nbsamples))*np.nan\n",
    "sus_all = np.zeros((nz,ny,nx,nbsamples))*np.nan\n",
    "rho_all = np.zeros((nz,ny,nx,nbsamples))*np.nan\n",
    "\n",
    "# get random sample urls for data to dowanload\n",
    "samples_ix=(np.round(np.random.uniform(0,1,nbsamples) * (nbmodels-1))). astype(int)\n",
    "models.loc[samples_ix,'event_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loading https://cloudstor.aarnet.edu.au/plus/s/8ZT6tjOvoLWmLPx/download?path=%2fFOLD_FOLD_FOLD&files=20-09-13-11-43-12-006536815 data.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading https://cloudstor.aarnet.edu.au/plus/s/8ZT6tjOvoLWmLPx/download?path=%2fTILT_PLUG_TILT&files=20-09-12-04-45-00-531746729 data.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each sample\n",
    "for s in range(nbsamples):\n",
    "    root = models.loc[samples_ix[s],'url']\n",
    "    display('loading '+root+' data.')\n",
    "    # download gravity response\n",
    "    path = root+'.grv.gz'\n",
    "    grv_all[:,:,s] = get_gz_array(path,skiprows=8)\n",
    "    # download magnetic response\n",
    "    path = root+'.mag.gz'\n",
    "    mag_all[:,:,s] = get_gz_array(path,skiprows=8)\n",
    "    # download litho code model\n",
    "    path = root + '.g12.gz'\n",
    "    tmp = get_gz_array(path,skiprows=0).astype(int)\n",
    "    mod = tmp.reshape((nz,nx,ny))\n",
    "    mod = np.transpose(mod,(0,2,1))\n",
    "    mod_all[:,:,:,s] = mod\n",
    "    # download properties\n",
    "    path = root + '.g00.gz'\n",
    "    my_gzip_stream = urlopen(path)\n",
    "    my_stream = gzip.open(my_gzip_stream, 'r')\n",
    "    txt = my_stream.readlines()[417:]\n",
    "    tmp = str(txt[0]).rsplit(' = ')[-1]\n",
    "    nbrocks = int(tmp.rsplit('\\\\')[0])\n",
    "    litho_cod = (np.zeros(nbrocks)).astype(int)\n",
    "    litho_lab = [] #np.chararray(nbrocks)\n",
    "    litho_rho = np.zeros(nbrocks)*np.nan\n",
    "    litho_sus = np.zeros(nbrocks)*np.nan\n",
    "\n",
    "    for r in range(nbrocks):\n",
    "        pos = r*3\n",
    "        tmp = str(txt[pos+1]).rsplit('ROCK DEFINITION ')[-1]\n",
    "        lab = tmp.split(' = ')[0]\n",
    "        cod = int((tmp.split(' = ')[1]).rsplit('\\\\')[0])\n",
    "        tmp = str(txt[pos+2]).rsplit('Density = ')[-1]\n",
    "        rho = float(tmp.rsplit('\\\\')[0])\n",
    "        tmp = str(txt[pos+3]).rsplit('Sus = ')[-1]\n",
    "        sus = float(tmp.rsplit('\\\\')[0])\n",
    "        litho_cod[r] = cod\n",
    "        litho_lab.append(lab)\n",
    "        litho_rho[r] = rho\n",
    "        litho_sus[r] = sus\n",
    "        del cod,lab,rho,sus\n",
    "       \n",
    "    # assign density and magnetic susceptibility\n",
    "    rho = np.zeros(mod.shape) * np.nan\n",
    "    sus = np.zeros(mod.shape) * np.nan\n",
    "    for r in range(nbrocks):\n",
    "        ix = np.where(mod==litho_cod[r])\n",
    "        rho[ix] = litho_rho[r]\n",
    "        sus[ix] = litho_sus[r]    \n",
    "\n",
    "    rho_all[:,:,:,s] = rho\n",
    "    sus_all[:,:,:,s] = sus\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property field plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 3 # a number < nb_samples\n",
    "print((datetime.now()).strftime('%d-%b-%Y (%H:%M:%S)')+\" - \"+\"PLOT FOR SAMPLE #\"+str(sample_num))\n",
    "tmp_grv = grv_all[:,:,sample_num]\n",
    "tmp_mag = mag_all[:,:,sample_num]\n",
    "tmp_mod = mod_all[:,:,:,sample_num]\n",
    "tmp_rho = rho_all[:,:,:,sample_num]\n",
    "tmp_sus = sus_all[:,:,:,sample_num]\n",
    "vmin = np.amin(tmp_mod)\n",
    "vmax = np.amax(tmp_mod)\n",
    "\n",
    "fig, ax = plt.subplots(2,6) #,figsize=(13,13)\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].axis('off')\n",
    "ax[0,2].axis('off')\n",
    "ax[0,3].axis('off')\n",
    "ax[0,4].axis('off')\n",
    "ax[0,5].axis('off')\n",
    "ax[1,0].axis('off')\n",
    "ax[1,1].axis('off')\n",
    "ax[1,2].axis('off')\n",
    "ax[1,3].axis('off')\n",
    "ax[1,4].axis('off')\n",
    "ax[1,5].axis('off')\n",
    "ax[0,1].set_title('Mag' ) #title.set_text\n",
    "ax[0,2].set_title('Grav')\n",
    "ax[0,3].set_title('Map')\n",
    "ax[0,4].set_title('W    (N)    E')\n",
    "ax[0,5].set_title('N    (W)    S')\n",
    "ax[1,0].set_title('density Map')\n",
    "ax[1,1].set_title('density W (N) E')\n",
    "ax[1,2].set_title('density N (W) S')\n",
    "ax[1,3].set_title('mag. susc. Map')\n",
    "ax[1,4].set_title('susc. W (N) E')\n",
    "ax[1,5].set_title('susc. N (W) S')\n",
    "ax[0,1].imshow(tmp_mag,cmap='rainbow')\n",
    "ax[0,2].imshow(tmp_grv,cmap='rainbow')\n",
    "ax[0,3].imshow(tmp_mod[0,:,:],cmap=cmap, interpolation=\"nearest\",vmin=vmin,vmax=vmax)\n",
    "ax[0,4].imshow(tmp_mod[:,0,:],cmap=cmap, interpolation=\"nearest\",vmin=vmin,vmax=vmax)\n",
    "ax[0,5].imshow(tmp_mod[:,:,0],cmap=cmap, interpolation=\"nearest\",vmin=vmin,vmax=vmax)\n",
    "ax[1,0].imshow(tmp_rho[0,:,:],cmap='rainbow')\n",
    "ax[1,1].imshow(tmp_rho[:,0,:],cmap='rainbow')\n",
    "ax[1,2].imshow(tmp_rho[:,:,0],cmap='rainbow')\n",
    "ax[1,3].imshow(tmp_sus[0,:,:],cmap='rainbow')\n",
    "ax[1,4].imshow(tmp_sus[:,0,:],cmap='rainbow')\n",
    "ax[1,5].imshow(tmp_sus[:,:,0],cmap='rainbow')\n",
    "fig.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.05, wspace=0.1, hspace=0.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save downloaded data for indicator computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(picklefilename, 'wb') as f:\n",
    "    pickle.dump([grv_all,mag_all,mod_all,rho_all,sus_all,cmap,samples_ix], f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty voxets or maps\n",
    "The indicator dimensions are the same as the property-field dimensions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardinality (uncertainty voxet or map)\n",
    "See [Cardinality notebook](./nbk-cardinality.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy (uncertainty voxet or map)\n",
    "See [Entropy notebook](./nbk-entropy.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance-based indicators\n",
    "In that case, the dimensionality is proportional to the size of the ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n",
    "See [Histogram notebook](./nbk-hist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-variogram\n",
    "See [Semi-variogram](./nbk-semivariogram.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectivity\n",
    "See [Connectivity notebook](./nbk-connectivity.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-point histograms (MPH)\n",
    "See [MPH notebook](./nbk-mph.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet decomposition\n",
    "See [Wavelet notebook](./nbk-wavelet.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topology\n",
    "See [Topology notebook](nbk-topology.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator comparison and visualization<span style='color:red'>\\*</span>\n",
    "<span style='color:red'>**\\*requires to run the Cardinality and Entropy notebooks entirely first** </span>\n",
    "\n",
    "See [Comparison plot notebook](./nbk-all-indicators-comparison.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
